{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p dev/results\n",
    "\n",
    "!wget -O dev/results/de_novo_results.zip \"https://zenodo.org/records/16438770/files/de_novo_results.zip?download=1\" \\\n",
    "    && unzip -o dev/results/de_novo_results.zip -d dev/results/ \\\n",
    "    && rm dev/results/de_novo_results.zip\n",
    "\n",
    "!wget -O dev/test_data.zip \"https://zenodo.org/records/16438770/files/test_datasets.zip?download=1\" \\\n",
    "  && unzip dev/test_data.zip -d dev/ \\\n",
    "  && rm dev/test_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# prepare custom DB inputs for sirius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seismiq_predictions_files = [\n",
    "    \"dev/results/de_novo_results/52969670_seismiq_pretrained-casmi_2016.pkl\",\n",
    "    \"dev/results/de_novo_results/52969679_seismiq_pretrained-casmi_2017.pkl\",\n",
    "    \"dev/results/de_novo_results/52969691_seismiq_pretrained-casmi_2022.pkl\",\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for yr, preds in zip ([\"2016\", \"2017\", \"2022\"], seismiq_predictions_files):\n",
    "    print('preparing sirius db input for casmi', yr)\n",
    "\n",
    "    with open(preds, \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "    with open(f\"dev/test_datasets/casmi_{yr}.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    df = (\n",
    "        pd.DataFrame(data)\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"smiles\": \"true_smiles\",\n",
    "            }\n",
    "        )\n",
    "        .merge(\n",
    "            df,\n",
    "            on=[\"challenge\", \"dataset\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        df.assign(\n",
    "            # parse smiles\n",
    "            true_mol=lambda d: d[\"true_smiles\"].apply(Chem.MolFromSmiles),\n",
    "            pred_mol=lambda d: d[\"pred_smiles\"].apply(Chem.MolFromSmiles),\n",
    "        ).loc[\n",
    "            # exclude invalid predicted smiles\n",
    "            lambda d: d[\"pred_mol\"].notna()\n",
    "        ]\n",
    "        .loc[\n",
    "            # exclude charged molecules - unsupported by sirius\n",
    "            lambda d: d[\"pred_mol\"].apply(lambda m: Chem.GetFormalCharge(m) == 0)\n",
    "        ]\n",
    "        .loc[\n",
    "            # exclude molecules with the wrong sum formula\n",
    "            lambda d: d[\"true_mol\"]\n",
    "            .apply(CalcMolFormula)\n",
    "            .eq(d[\"pred_mol\"].apply(CalcMolFormula))\n",
    "        ]\n",
    "        .assign(\n",
    "            pred_smiles=lambda d: d['pred_mol'].apply(Chem.MolToSmiles),\n",
    "            sirius_db_id=lambda d: d.apply(\n",
    "                lambda row: f\"{row['dataset']}-{row['challenge']}-pred-{row['index']}\", axis=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "    df[[\"pred_smiles\", \"sirius_db_id\", \"sirius_db_id\"]].to_csv(\n",
    "        f\"dev/sirius_db_input-casmi_{yr}.tsv\", index=False, sep=\"\\t\", header=False\n",
    "    )\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Produce SIRIUS ranking through GUI\n",
    "\n",
    "Import the DB produced above, then import spectral data and perform structure search against that DB.\n",
    "\n",
    "Here we download the resulting files from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O dev/results/sirius_ranking.zip \"https://zenodo.org/records/16438770/files/sirius_ranking.zip?download=1\" \\\n",
    "    && unzip -o dev/results/sirius_ranking.zip -d dev/results/ \\\n",
    "    && rm dev/results/sirius_ranking.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Analyze SIRIUS ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirius = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f'dev/results/sirius_ranking/sirius_casmi_{yr}_summary/structure_identifications_all.tsv', sep=\"\\t\")\n",
    "        for yr in [\"2016\", \"2017\", \"2022\"]\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# canonicalize smiles\n",
    "df_sirius = df_sirius.assign(\n",
    "    mol=lambda d: d[\"smiles\"].apply(Chem.MolFromSmiles),\n",
    "    smiles=lambda d: d[\"mol\"].apply(lambda m: Chem.MolToSmiles(m) if m else None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.merge(\n",
    "    df,\n",
    "    df_sirius,\n",
    "    left_on=\"pred_smiles\",\n",
    "    right_on=\"smiles\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = (\n",
    "    df_results[\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"challenge\",\n",
    "            \"true_smiles\",\n",
    "            \"pred_smiles\",\n",
    "            \"perplexity\",\n",
    "            \"tanimoto\",\n",
    "            \"CSI:FingerIDScore\",\n",
    "            \"index\",\n",
    "            \"structurePerIdRank\",\n",
    "        ]\n",
    "    ]\n",
    "    .assign(\n",
    "        perfect=lambda d: d['tanimoto'] > 0.9999\n",
    "    )\n",
    ")\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i, g in df_results.dropna().groupby([\"dataset\", \"challenge\"]):\n",
    "    g = g.assign(\n",
    "        seismiq_rank=g['perplexity'].rank(ascending=True, method='dense'),\n",
    "        sirius_rank=g['CSI:FingerIDScore'].rank(ascending=False, method='dense'),\n",
    "    )\n",
    "    rr = pd.DataFrame([{\n",
    "        'k': k,\n",
    "        'seismiq_perfect': g.loc[g['seismiq_rank'] <= k, 'tanimoto'].gt(0.999).max(),\n",
    "        'sirius_perfect': g.loc[g['sirius_rank'] <= k, 'tanimoto'].gt(0.999).max()\n",
    "    } for k in [1, 5, 10, 25]])\n",
    "    rr[['dataset', 'challenge']] = i\n",
    "    rows.append(rr)\n",
    "\n",
    "\n",
    "dfk = pd.concat(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import permutation_test\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "for dataset, group in dfk.groupby('dataset'):\n",
    "    for k, gk in group.groupby('k'):\n",
    "        # permutation test for difference in means\n",
    "        res = permutation_test(\n",
    "            (gk['seismiq_perfect'].values, gk['sirius_perfect'].values),\n",
    "            statistic=lambda x, y: x.mean() - y.mean(),\n",
    "            permutation_type='samples',\n",
    "            n_resamples=10000,\n",
    "            alternative='two-sided',\n",
    "            #vectorized=True,\n",
    "            random_state=82746,\n",
    "        )\n",
    "        results.append({\n",
    "            'dataset': dataset,\n",
    "            'k': k,\n",
    "            'seismiq_mean': gk['seismiq_perfect'].mean(),\n",
    "            'sirius_mean': gk['sirius_perfect'].mean(),\n",
    "            'pvalue': res.pvalue,\n",
    "            'statistic': res.statistic,\n",
    "        })\n",
    "\n",
    "df_significance = pd.DataFrame(results).assign(\n",
    "    sig=lambda d: d['pvalue'].apply(\n",
    "        lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else '.' if p < 0.1 else 'n.s.'\n",
    "    ),\n",
    "    mark=lambda d: np.where(d['pvalue'] < 0.05, \"(*)\", \"\"),\n",
    ")\n",
    "\n",
    "df_significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "g = dfk.melt(\n",
    "    id_vars=[\"dataset\", \"challenge\", \"k\"],\n",
    "    value_vars=[\"sirius_perfect\", \"seismiq_perfect\"],\n",
    ").replace({\n",
    "    'dataset': {\n",
    "        'casmi_2016': 'CASMI 2016',\n",
    "        'casmi_2017': 'CASMI 2017',\n",
    "        'casmi_2022': 'CASMI 2022',\n",
    "    },\n",
    "    'variable': {\n",
    "        'sirius_perfect': 'CSI:FingerID',\n",
    "        'seismiq_perfect': 'SEISMiQ',\n",
    "    }\n",
    "}).rename(\n",
    "    columns={\n",
    "        'variable': 'Ranking',\n",
    "        'value': 'Accuracy',\n",
    "        'k': 'Top-k',\n",
    "    }\n",
    ").pipe(\n",
    "    (sns.catplot, 'data'),\n",
    "    x='Top-k',\n",
    "    y='Accuracy',\n",
    "    hue='Ranking',\n",
    "    col='dataset',\n",
    "    kind='bar',\n",
    "    errorbar='se',\n",
    "    sharey=False,\n",
    "    height=3,\n",
    "    aspect=1.25,\n",
    ")\n",
    "\n",
    "# Annotate significance at the top of each Top-k group, above the highest bar\n",
    "for ax, dataset in zip(g.axes.flat, g.col_names):\n",
    "    dataset_key = dataset.replace(' ', '_').lower()\n",
    "\n",
    "    y_pos = max(\n",
    "        bar.get_height()\n",
    "        for container in ax.containers\n",
    "        for bar in container\n",
    "    )\n",
    "\n",
    "    # annotate statistical significance\n",
    "    for i, k in enumerate(sorted(df_significance[df_significance['dataset'] == dataset_key]['k'])):\n",
    "        sig = df_significance[(df_significance['dataset'] == dataset_key) & (df_significance['k'] == k)]['sig'].values[0]\n",
    "        ax.text(i, y_pos + 0.07, sig, ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    ax.set_ylim(0, y_pos + 0.14)\n",
    "\n",
    "    ax.set_title(ax.get_title().replace('dataset = ', ''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
